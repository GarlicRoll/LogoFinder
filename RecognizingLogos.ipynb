{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 1508223,
     "sourceType": "datasetVersion",
     "datasetId": 888440
    }
   ],
   "dockerImageVersionId": 30684,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense, Input, Concatenate\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
    "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir, pred_and_plot"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-10T01:40:40.058564Z",
     "iopub.execute_input": "2024-04-10T01:40:40.058824Z",
     "iopub.status.idle": "2024-04-10T01:40:54.534026Z",
     "shell.execute_reply.started": "2024-04-10T01:40:40.058800Z",
     "shell.execute_reply": "2024-04-10T01:40:54.532931Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": "2024-04-10 01:40:42.663432: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-10 01:40:42.663540: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-10 01:40:42.803497: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "--2024-04-10 01:40:53--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 10246 (10K) [text/plain]\nSaving to: 'helper_functions.py'\n\nhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n\n2024-04-10 01:40:54 (61.4 MB/s) - 'helper_functions.py' saved [10246/10246]\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "store_names = []\n",
    "directory = \"/kaggle/input/logodet3k/LogoDet-3K/Food\"\n",
    "for item in os.listdir(directory):\n",
    "    item_path = os.path.join(directory, item)\n",
    "    if os.path.isdir(item_path):\n",
    "        store_names.append(item)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-10T01:40:54.536529Z",
     "iopub.execute_input": "2024-04-10T01:40:54.538013Z",
     "iopub.status.idle": "2024-04-10T01:40:54.681784Z",
     "shell.execute_reply.started": "2024-04-10T01:40:54.537982Z",
     "shell.execute_reply": "2024-04-10T01:40:54.680974Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_model(input_image_shape, input_xml_shape, num_classes):\n",
    "    # Pretrained model\n",
    "    \n",
    "    pretrained_model = tf.keras.applications.EfficientNetB0(\n",
    "        input_shape=(128, 128, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='max'\n",
    "    )\n",
    "\n",
    "    # Image input branch\n",
    "    image_input = Input(shape=input_image_shape)\n",
    "    image_branch = pretrained_model(image_input, training=False)  # Freeze pretrained layers\n",
    "\n",
    "    # XML input branch\n",
    "    xml_input = Input(shape=input_xml_shape)\n",
    "    xml_branch = Dense(128, activation='relu')(xml_input)\n",
    "\n",
    "    # Combine image and XML branches\n",
    "    combined = Concatenate()([image_branch, xml_branch])\n",
    "\n",
    "    # Output layer\n",
    "    output = Dense(num_classes, activation='softmax')(combined)\n",
    "\n",
    "    # Define the model\n",
    "    model = Model(inputs=[image_input, xml_input], outputs=output)\n",
    "    return model"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-10T01:40:54.683307Z",
     "iopub.execute_input": "2024-04-10T01:40:54.683661Z",
     "iopub.status.idle": "2024-04-10T01:40:54.691913Z",
     "shell.execute_reply.started": "2024-04-10T01:40:54.683632Z",
     "shell.execute_reply": "2024-04-10T01:40:54.690903Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def extract_label_and_bbox_from_xml(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    \n",
    "    # Extract label\n",
    "    label = root.find('object/name').text\n",
    "    \n",
    "    # Extract bounding box coordinates\n",
    "    xmin = int(root.find('object/bndbox/xmin').text)\n",
    "    ymin = int(root.find('object/bndbox/ymin').text)\n",
    "    xmax = int(root.find('object/bndbox/xmax').text)\n",
    "    ymax = int(root.find('object/bndbox/ymax').text)\n",
    "    bbox = [xmin, ymin, xmax, ymax]\n",
    "    \n",
    "    return label, bbox"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-10T01:40:54.694278Z",
     "iopub.execute_input": "2024-04-10T01:40:54.694616Z",
     "iopub.status.idle": "2024-04-10T01:40:54.702809Z",
     "shell.execute_reply.started": "2024-04-10T01:40:54.694587Z",
     "shell.execute_reply": "2024-04-10T01:40:54.701908Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data = []\n",
    "\n",
    "total_files = sum(len(files) for _, _, files in os.walk(directory)) // 2\n",
    "files_processed = 0\n",
    "\n",
    "for label, store_name in enumerate(store_names):\n",
    "    store_path = os.path.join(directory, store_name)  \n",
    "    for file in os.listdir(store_path):\n",
    "        # Filter out non-image files\n",
    "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            img_path = os.path.join(store_path, file)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "            img = cv2.resize(img, (128, 128))\n",
    "            # Extract label and bounding box from corresponding XML file\n",
    "            xml_file = file[:-4] + '.xml'  # Assuming XML file has the same name as the image file\n",
    "            xml_path = os.path.join(store_path, xml_file)\n",
    "            _, bbox = extract_label_and_bbox_from_xml(xml_path)\n",
    "            data.append([img, label, bbox])\n",
    "            \n",
    "             # Increment the count of processed files\n",
    "            files_processed += 1\n",
    "            # Print progress every 10% of completion\n",
    "            if files_processed % (total_files // 10) == 0:\n",
    "                print(f\"Progress: {files_processed}/{total_files} files processed ({files_processed / total_files * 100:.0f}%)\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-10T01:40:54.704073Z",
     "iopub.execute_input": "2024-04-10T01:40:54.704364Z",
     "iopub.status.idle": "2024-04-10T01:54:19.173698Z",
     "shell.execute_reply.started": "2024-04-10T01:40:54.704339Z",
     "shell.execute_reply": "2024-04-10T01:54:19.172743Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": "Progress: 10670/53350 files processed (20%)\nProgress: 16005/53350 files processed (30%)\nProgress: 21340/53350 files processed (40%)\nProgress: 26675/53350 files processed (50%)\nProgress: 32010/53350 files processed (60%)\nProgress: 37345/53350 files processed (70%)\nProgress: 42680/53350 files processed (80%)\nProgress: 48015/53350 files processed (90%)\nProgress: 53350/53350 files processed (100%)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "X = []\n",
    "Y = []\n",
    "XML = []\n",
    "for features,label,xml in data:\n",
    "    X.append([features, xml])\n",
    "    Y.append(label)\n",
    "xtrainD,xtestD,ytrain,ytest = train_test_split(X,Y,test_size=0.2,random_state=56)\n",
    "xtrain = np.array([a[0] for a in xtrainD])\n",
    "xtest = np.array([a[0] for a in xtestD])\n",
    "xtrain_xml = np.array([a[1] for a in xtrainD])\n",
    "xtest_xml = np.array([a[1] for a in xtestD])\n",
    "\n",
    "ytrain = np.array(ytrain)\n",
    "ytest = np.array(ytest)\n",
    "\n",
    "ytrain = to_categorical(ytrain,len(store_names))\n",
    "ytest = to_categorical(ytest,len(store_names))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-10T01:54:19.174920Z",
     "iopub.execute_input": "2024-04-10T01:54:19.175301Z",
     "iopub.status.idle": "2024-04-10T01:54:20.553799Z",
     "shell.execute_reply.started": "2024-04-10T01:54:19.175276Z",
     "shell.execute_reply": "2024-04-10T01:54:20.552794Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Create checkpoint callback\n",
    "checkpoint_path = \"classification_model_checkpoint.weights.h5\"\n",
    "checkpoint_callback = ModelCheckpoint(checkpoint_path,\n",
    "                                      save_weights_only=True,\n",
    "                                      monitor=\"val_accuracy\",\n",
    "                                      save_best_only=True)\n",
    "\n",
    "# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\n",
    "early_stopping = EarlyStopping(monitor = \"val_loss\", # watch the val loss metric\n",
    "                               patience = 7,\n",
    "                               restore_best_weights = True) # if val loss decreases for 3 epochs in a row, stop training\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-10T01:54:20.554941Z",
     "iopub.execute_input": "2024-04-10T01:54:20.555211Z",
     "iopub.status.idle": "2024-04-10T01:54:20.560685Z",
     "shell.execute_reply.started": "2024-04-10T01:54:20.555189Z",
     "shell.execute_reply": "2024-04-10T01:54:20.559776Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "input_image_shape = xtrain.shape[1:]  # Shape of input images\n",
    "input_xml_shape = (4,)  # Shape of input XML data (adjust according to your data)\n",
    "num_classes = len(store_names)  # Number of output classes\n",
    "nn = create_model(input_image_shape, input_xml_shape, num_classes)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-10T01:54:20.561825Z",
     "iopub.execute_input": "2024-04-10T01:54:20.562085Z",
     "iopub.status.idle": "2024-04-10T01:54:24.124147Z",
     "shell.execute_reply.started": "2024-04-10T01:54:20.562064Z",
     "shell.execute_reply": "2024-04-10T01:54:24.123383Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n\u001B[1m16705208/16705208\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 0us/step\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "nn.compile(loss='categorical_crossentropy',optimizer='adam',metrics=[\"accuracy\"])\n",
    "final_model = nn.fit([xtrain, xtrain_xml],\n",
    "                     ytrain,\n",
    "                     validation_data=([xtest, xtest_xml], ytest),\n",
    "                     epochs=100,\n",
    "                    callbacks=[\n",
    "                        early_stopping,\n",
    "                        create_tensorboard_callback(\"training_logs\", \n",
    "                                    \"classification\"),\n",
    "                        checkpoint_callback,\n",
    "                        reduce_lr\n",
    "    ])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-10T01:54:24.125201Z",
     "iopub.execute_input": "2024-04-10T01:54:24.125458Z",
     "iopub.status.idle": "2024-04-10T02:18:07.040842Z",
     "shell.execute_reply.started": "2024-04-10T01:54:24.125436Z",
     "shell.execute_reply": "2024-04-10T02:18:07.039947Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": "Saving TensorBoard log files to: training_logs/classification/20240410-015424\nEpoch 1/100\n\u001B[1m1334/1334\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m215s\u001B[0m 99ms/step - accuracy: 0.1609 - loss: 8.4859 - val_accuracy: 0.5348 - val_loss: 2.3821 - learning_rate: 0.0010\nEpoch 2/100\n\u001B[1m1334/1334\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m70s\u001B[0m 52ms/step - accuracy: 0.6235 - loss: 1.7704 - val_accuracy: 0.6602 - val_loss: 1.7256 - learning_rate: 0.0010\nEpoch 3/100\n\u001B[1m1334/1334\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m70s\u001B[0m 52ms/step - accuracy: 0.7656 - loss: 0.9841 - val_accuracy: 0.6978 - val_loss: 1.5386 - learning_rate: 0.0010\nEpoch 4/100\n\u001B[1m1334/1334\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m70s\u001B[0m 52ms/step - accuracy: 0.8275 - loss: 0.6698 - val_accuracy: 0.7078 - val_loss: 1.5381 - learning_rate: 0.0010\nEpoch 5/100\n\u001B[1m1334/1334\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m70s\u001B[0m 52ms/step - accuracy: 0.8683 - loss: 0.4918 - val_accuracy: 0.7351 - val_loss: 1.5194 - learning_rate: 0.0010\nEpoch 6/100\n\u001B[1m1334/1334\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m69s\u001B[0m 52ms/step - accuracy: 0.8898 - loss: 0.3895 - val_accuracy: 0.7088 - val_loss: 1.6930 - learning_rate: 0.0010\nEpoch 7/100\n\u001B[1m1334/1334\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m70s\u001B[0m 53ms/step - accuracy: 0.9143 - loss: 0.2922 - val_accuracy: 0.7501 - val_loss: 1.6904 - learning_rate: 0.0010\nEpoch 9/100\n\u001B[1m1334/1334\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m70s\u001B[0m 53ms/step - accuracy: 0.9557 - loss: 0.1346 - val_accuracy: 0.8108 - val_loss: 1.2683 - learning_rate: 2.0000e-04\nEpoch 10/100\n\u001B[1m1334/1334\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m72s\u001B[0m 54ms/step - accuracy: 0.9810 - loss: 0.0479 - val_accuracy: 0.8157 - val_loss: 1.2763 - learning_rate: 2.0000e-04\nEpoch 11/100\n\u001B[1m1334/1334\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m71s\u001B[0m 53ms/step - accuracy: 0.9817 - loss: 0.0428 - val_accuracy: 0.8162 - val_loss: 1.2489 - learning_rate: 2.0000e-04\nEpoch 12/100\n\u001B[1m1334/1334\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m71s\u001B[0m 53ms/step - accuracy: 0.9808 - loss: 0.0447 - val_accuracy: 0.8145 - val_loss: 1.3106 - learning_rate: 2.0000e-04\nEpoch 13/100\n\u001B[1m1334/1334\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m72s\u001B[0m 54ms/step - accuracy: 0.9838 - loss: 0.0370 - val_accuracy: 0.8159 - val_loss: 1.3211 - learning_rate: 2.0000e-04\nEpoch 14/100\n\u001B[1m1334/1334\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m73s\u001B[0m 54ms/step - accuracy: 0.9821 - loss: 0.0392 - val_accuracy: 0.8139 - val_loss: 1.3568 - learning_rate: 2.0000e-04\nEpoch 15/100\n\u001B[1m1334/1334\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m71s\u001B[0m 53ms/step - accuracy: 0.9844 - loss: 0.0322 - val_accuracy: 0.8173 - val_loss: 1.3386 - learning_rate: 4.0000e-05\nEpoch 16/100\n\u001B[1m1334/1334\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m73s\u001B[0m 55ms/step - accuracy: 0.9854 - loss: 0.0254 - val_accuracy: 0.8185 - val_loss: 1.3516 - learning_rate: 4.0000e-05\nEpoch 17/100\n\u001B[1m1334/1334\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m71s\u001B[0m 53ms/step - accuracy: 0.9856 - loss: 0.0246 - val_accuracy: 0.8193 - val_loss: 1.3630 - learning_rate: 4.0000e-05\nEpoch 18/100\n\u001B[1m1334/1334\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m70s\u001B[0m 53ms/step - accuracy: 0.9868 - loss: 0.0228 - val_accuracy: 0.8203 - val_loss: 1.3653 - learning_rate: 8.0000e-06\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Saving the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "nn.save(\"nn128.keras\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-10T02:18:07.043781Z",
     "iopub.execute_input": "2024-04-10T02:18:07.044079Z",
     "iopub.status.idle": "2024-04-10T02:18:07.879343Z",
     "shell.execute_reply.started": "2024-04-10T02:18:07.044054Z",
     "shell.execute_reply": "2024-04-10T02:18:07.878531Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "nn.save_weights(\"nn128.weights.h5\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-10T02:18:07.880434Z",
     "iopub.execute_input": "2024-04-10T02:18:07.880705Z",
     "iopub.status.idle": "2024-04-10T02:18:08.492494Z",
     "shell.execute_reply.started": "2024-04-10T02:18:07.880683Z",
     "shell.execute_reply": "2024-04-10T02:18:08.491683Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "op = cv2.imread('/kaggle/input/logodet3k/LogoDet-3K/Food/7-Up/12.jpg')\n",
    "op = cv2.resize(op,(128,128))\n",
    "op = np.array(op)\n",
    "#op = op.reshape(1,30,30,3)\n",
    "\n",
    "\n",
    "\n",
    "x_min, y_min = 5, 10\n",
    "x_max, y_max = 20, 25\n",
    "op_xml = np.array([x_min, x_max, y_min, y_max])\n",
    "op_image = np.array(op).reshape(1, *op.shape)\n",
    "op_xml = np.array(op_xml).reshape(1, *op_xml.shape)\n",
    "\n",
    "model = nn.predict([op_image, op_xml])\n",
    "\n",
    "# Convert to DataFrame\n",
    "val = []\n",
    "for i in model:\n",
    "    val.append(i)\n",
    "data_fram = pd.DataFrame([store_names,val[0]]).T\n",
    "data_fram.columns = [\"Outlate\",\"Output\"]\n",
    "\n",
    "# Final Output\n",
    "op_final = data_fram.groupby('Output').max().tail(1).values[0][0]\n",
    "\n",
    "predicted_class_index = np.argmax(model)\n",
    "\n",
    "    # Get the predicted class associated probability\n",
    "probability = model.squeeze()[predicted_class_index] * 100  # Convert to percentage\n",
    "print(f\"Given Image is {op_final} Store with a probability of {probability:.2f}%\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-10T02:18:08.493871Z",
     "iopub.execute_input": "2024-04-10T02:18:08.494169Z",
     "iopub.status.idle": "2024-04-10T02:18:15.522023Z",
     "shell.execute_reply.started": "2024-04-10T02:18:08.494145Z",
     "shell.execute_reply": "2024-04-10T02:18:15.520994Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 7s/step\nGiven Image is 7-Up Store with a probability of 99.95%\n",
     "output_type": "stream"
    }
   ]
  }
 ]
}
